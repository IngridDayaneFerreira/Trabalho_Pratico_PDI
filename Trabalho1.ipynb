{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho 1 - PDI\n",
    "### Ingrid Dayane da Silva Ferreira (20200154050)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desenvolva, em uma linguagem de programação de sua escolha, um sistema para abrir, \n",
    "exibir, manipular e salvar imagens RGB com 24 bits/pixel (8 bits/componente/pixel). Não \n",
    "use bibliotecas ou funções especiais de processamento de imagens. O sistema deve ter a \n",
    "seguinte funcionalidade:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Correlação m x n com offset, sobre R, G e B. O offset e o filtro (dimensões e valores \n",
    "da máscara) devem ser definidos em um arquivo (txt) à parte. Realize testes com os \n",
    "filtros Gaussiano 5x5, Sobel horizontal e Sobel vertical, e explique os resultados.\n",
    "Utilize extensão por zeros. Para visualização do Sobel, aplique valor absoluto seguido \n",
    "por expansão de histograma para [0, 255]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(i, f, nome_resultado):\n",
    "    # importando as bibliotecas necessárias ao processamento\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "\n",
    "    # leitura do txt com as informações do filtro\n",
    "    with open(f, 'r') as file:  # abrindo o txt do filtro\n",
    "        m = int(file.readline()) # linhas\n",
    "        n = int(file.readline()) # colunas\n",
    "        offset = int(file.readline().strip())\n",
    "        filtro = [[0] * n for _ in range(m)] # criando uma matriz para colocar o filtro\n",
    "        linhas = file.readlines()\n",
    "\n",
    "        for j, line in enumerate(linhas): # colocando o filtro na matriz criada\n",
    "            f1 = (line.split())\n",
    "            filtro[j] = [float(valor) for valor in f1]\n",
    "\n",
    "    img = cv2.imread(i) # lendo a imagem\n",
    "    img_m, img_n, _ = img.shape # terceira dimensão = bandas (B,G,R)\n",
    "\n",
    "    img_resultante = np.zeros_like(img) # gerando uma imagem resultante de mesmo tamanho da imagem de entrada\n",
    "\n",
    "    # Separando os canais\n",
    "    B = img[:,:,0]\n",
    "    G = img[:,:,1]\n",
    "    R = img[:,:,2]\n",
    "\n",
    "    # criando imagens vazias para alocar o resultado de B, G e R\n",
    "    B_result = np.zeros_like(B)\n",
    "    G_result = np.zeros_like(G)\n",
    "    R_result = np.zeros_like(R)\n",
    "\n",
    "    for b, b_result in zip([B, G, R],[B_result,G_result,R_result]): # Aplicando o filtro em cada canal\n",
    "        maximo = np.max(b)\n",
    "        minimo = np.min(b)\n",
    "        padded_b = np.pad(b, ((m//2, m//2), (n//2, n//2)),'constant',constant_values=0) # extensão pr zero\n",
    "        for q in range(img_m): # aplicar o filtro em cada posição da imagem\n",
    "            for w in range(img_n):\n",
    "                vizinhanca = padded_b[q:q+m,w:w+n] # recortando a vizinhança para realizar a convolução do filtro (considerando a extensão por zero)\n",
    "                vizinhanca = ((vizinhanca - minimo)/(maximo - minimo))*255 # aplicando a expansão de histograma com foco na vizinhança\n",
    "                vizinhanca = vizinhanca.astype('int')\n",
    "                pos = np.sum(vizinhanca * filtro) + offset #aplicando o filtro na posição (q,w)\n",
    "                b_result[q,w] = np.absolute(pos) # valor absoluto\n",
    "                b_result[q,w] = np.clip(b_result[q,w],-255,255) # Delimitando o valor absoluto de -255 a 255\n",
    "                b_result[q,w] = b_result[q,w].astype('int') #converte para inteiro\n",
    "\n",
    "    # merge das bandas\n",
    "    img_resultante[:,:,0] = B_result\n",
    "    img_resultante[:,:,1] = G_result\n",
    "    img_resultante[:,:,2] = R_result\n",
    "\n",
    "    # gera um arquivo\n",
    "    resultado = cv2.imwrite(nome_resultado, img_resultante)\n",
    "\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = filter('Shapes.png','Gaussiano_5x5.txt','Shapes_Gaussiano_5x5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = filter('Shapes.png','Sobel_h.txt','Shapes_Sobel_h.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = filter('Shapes.png','Sobel_v.txt','Shapes_Sobel_v.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultado = filter('Shapes.png','BOX_10x10.txt','Shapes_BOX_10x10.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = filter('testpat.tif','Gaussiano_5x5.txt','testpat_Gaussiano_5x5.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = filter('testpat.tif','Sobel_h.txt','testpat_Sobel_h.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = filter('testpat.tif','Sobel_v.txt','testpat_Sobel_v.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Filtro pontual a seguir \n",
    "\n",
    "![Filtro Pontual](Filtro_Pontual.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse filtro possui uma função do tipo: <br>\n",
    "y = 1,992x , para 0 < x <= 128 <br>\n",
    "y = -1,992x + 508 , para 128 < x < 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) aplicado em RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pontual_filter(i,nome_resultado):\n",
    "    # importando as bibliotecas necessárias ao processamento\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "\n",
    "    img = cv2.imread(i) # lendo a imagem\n",
    "    img_m, img_n, _ = img.shape # terceira dimensão = bandas (B,G,R)\n",
    "\n",
    "    img_resultante = np.zeros_like(img) # gerando uma imagem resultante de mesmo tamanho da imagem de entrada\n",
    "\n",
    "    # Separando os canais\n",
    "    B = img[:,:,0]\n",
    "    G = img[:,:,1]\n",
    "    R = img[:,:,2]\n",
    "\n",
    "    # criando imagens vazias para alocar o resultado de B, G e R\n",
    "    B_result = np.zeros_like(B)\n",
    "    G_result = np.zeros_like(G)\n",
    "    R_result = np.zeros_like(R)\n",
    "\n",
    "    for b, b_result in zip([B,G,R],[B_result,G_result,R_result]): # Aplicando o filtro em cada canal\n",
    "        for q in range(img_m): # aplicar o filtro em cada posição da imagem\n",
    "            for w in range(img_n):\n",
    "                # As fórmulas foram calculadas no GeoGebra\n",
    "                if b[q,w] <= 128:\n",
    "                    b_result[q,w] = 1.992*b_result[q,w] \n",
    "                else:\n",
    "                    b_result[q,w] = np.clip((-1.992*b_result[q,w] + 508),0,255)\n",
    "\n",
    "    # # merge das bandas\n",
    "    img_resultante[:,:,0] = B_result\n",
    "    img_resultante[:,:,1] = G_result\n",
    "    img_resultante[:,:,2] = R_result\n",
    "\n",
    "    nome_B = nome_resultado + '_B.tif'\n",
    "    nome_G = nome_resultado + '_G.tif'\n",
    "    nome_R = nome_resultado + '_R.tif'\n",
    "\n",
    "    # gera um arquivo\n",
    "    resultado = cv2.imwrite(nome_resultado, img_resultante)\n",
    "    resultado = cv2.imwrite(nome_B, img_resultante[:,:,0])\n",
    "    resultado = cv2.imwrite(nome_G, img_resultante[:,:,1])\n",
    "    resultado = cv2.imwrite(nome_R, img_resultante[:,:,2])\n",
    "\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = pontual_filter('testpat.tif','testpat_Pontal.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = pontual_filter('color.png','color_Pontal.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) aplicado à banda Y do YIQ, com posterior conversão a RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2yiq(i, nome_resultado):\n",
    "    # importando as bibliotecas necessárias ao processamento\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "\n",
    "    img = cv2.imread(i) # lendo a imagem\n",
    "    img_m, img_n, _ = img.shape # terceira dimensão = bandas (B,G,R)\n",
    "\n",
    "    img_resultante = np.zeros_like(img) # gerando uma imagem resultante de mesmo tamanho da imagem de entrada\n",
    "\n",
    "    # Separando os canais\n",
    "    B = img[:,:,0]\n",
    "    G = img[:,:,1]\n",
    "    R = img[:,:,2]\n",
    "\n",
    "    # criando imagens vazias para alocar o resultado de B, G e R\n",
    "    Y = np.zeros_like(B)\n",
    "    I = np.zeros_like(G)\n",
    "    Q = np.zeros_like(R)\n",
    "\n",
    "    for q in range(img_m): # aplicar o filtro em cada posição da imagem\n",
    "        for w in range(img_n):\n",
    "            Y[q,w] = (0.299 * R[q,w]) + (0.587 * G[q,w]) + (0.114 * B[q,w])\n",
    "            I[q,w] = (0.596 * R[q,w]) - (0.274 * G[q,w]) - (0.322 * B[q,w])\n",
    "            Q[q,w] = (0.211 * R[q,w]) - (0.523 * G[q,w]) + (0.312 * B[q,w])\n",
    "\n",
    "    for q in range(img_m): # aplicar o filtro em cada posição da imagem\n",
    "        for w in range(img_n):\n",
    "            # As fórmulas foram calculadas no GeoGebra\n",
    "            if Y[q,w] <= 128:\n",
    "                Y[q,w] = 1.992*Y[q,w] \n",
    "            else:\n",
    "                Y[q,w] = np.clip((-1.992*Y[q,w] + 508),0,255)\n",
    "\n",
    "    # # merge das bandas\n",
    "    img_resultante[:,:,0] = Y\n",
    "    img_resultante[:,:,1] = I\n",
    "    img_resultante[:,:,2] = Q\n",
    "\n",
    "    nome_B = nome_resultado + '_Y.png'\n",
    "    nome_G = nome_resultado + '_I.png'\n",
    "    nome_R = nome_resultado + '_Q.png'\n",
    "\n",
    "    # gera um arquivo\n",
    "    resultado = cv2.imwrite(nome_resultado, img_resultante)\n",
    "    resultado = cv2.imwrite(nome_B, img_resultante[:,:,0])\n",
    "    resultado = cv2.imwrite(nome_G, img_resultante[:,:,1])\n",
    "    resultado = cv2.imwrite(nome_R, img_resultante[:,:,2])\n",
    "\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = rgb2yiq('testpat.tif','testpat_YIQ.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = rgb2yiq('color.png','color_YIQ.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yiq2rgb(i, nome_resultado):\n",
    "    # importando as bibliotecas necessárias ao processamento\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "\n",
    "    img = cv2.imread(i) # lendo a imagem\n",
    "    img_m, img_n, _ = img.shape # terceira dimensão = bandas (Y,I,Q)\n",
    "\n",
    "    img_resultante = np.zeros_like(img) # gerando uma imagem resultante de mesmo tamanho da imagem de entrada\n",
    "\n",
    "    # Separando os canais\n",
    "    Y = img[:,:,0]\n",
    "    I = img[:,:,1]\n",
    "    Q = img[:,:,2]\n",
    "\n",
    "    # criando imagens vazias para alocar o resultado de B, G e R\n",
    "    B = np.zeros_like(Y)\n",
    "    G = np.zeros_like(Y)\n",
    "    R = np.zeros_like(Y)\n",
    "\n",
    "    for q in range(img_m): # aplicar o filtro em cada posição da imagem\n",
    "        for w in range(img_n):\n",
    "            B[q,w] = (Y[q,w]) + (0.956 * I[q,w]) + (0.621 * Q[q,w])\n",
    "            G[q,w] = (Y[q,w]) - (0.272 * I[q,w]) - (0.647 * Q[q,w])\n",
    "            R[q,w] = (Y[q,w]) - (1.106 * I[q,w]) + (1.703 * Q[q,w])\n",
    "\n",
    "    # # merge das bandas\n",
    "    img_resultante[:,:,0] = B\n",
    "    img_resultante[:,:,1] = G\n",
    "    img_resultante[:,:,2] = R\n",
    "\n",
    "    nome_B = nome_resultado + '_B.png'\n",
    "    nome_G = nome_resultado + '_G.png'\n",
    "    nome_R = nome_resultado + '_R.png'\n",
    "\n",
    "    # gera um arquivo\n",
    "    resultado = cv2.imwrite(nome_resultado, img_resultante)\n",
    "    resultado = cv2.imwrite(nome_B, img_resultante[:,:,0])\n",
    "    resultado = cv2.imwrite(nome_G, img_resultante[:,:,1])\n",
    "    resultado = cv2.imwrite(nome_R, img_resultante[:,:,2])\n",
    "\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = yiq2rgb('testpat_YIQ.tif','testpat_volta_RGB.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = yiq2rgb('color_YIQ.png','color_volta_RGB.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
